{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    match = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return NaN\n",
    "#정규 표현식을 이용해 name에서 title을 추출 하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_age(cols):\n",
    "    age = cols[0]\n",
    "    title = cols[1]\n",
    "    if pd.isnull(age):\n",
    "        if title == 1:\n",
    "            return 32.376543\n",
    "        elif title == 3:\n",
    "            return 35.898148\n",
    "        elif title == 4:\n",
    "            return 21.773973\n",
    "        elif title == 5:\n",
    "            return 4.574167\n",
    "        elif title == 6:\n",
    "            return 53.250000\n",
    "        elif title == 7:\n",
    "            return 42.000000\n",
    "        elif title == 10:\n",
    "            return 45.222222\n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "#누락된 age값을 채우기 위해 각 title별 평균나이를 return하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Age  Survived\n",
      "Title                          \n",
      " Capt.      70.000000  0.000000\n",
      " Col.       58.000000  0.500000\n",
      " Countess.  33.000000  1.000000\n",
      " Don.       40.000000  0.000000\n",
      " Dr.        42.000000  0.428571\n",
      " Jonkheer.  38.000000  0.000000\n",
      " Lady.      48.000000  1.000000\n",
      " Major.     48.500000  0.500000\n",
      " Master.     4.574167  0.575000\n",
      " Miss.      21.773973  0.697802\n",
      " Mlle.      24.000000  1.000000\n",
      " Mme.       24.000000  1.000000\n",
      " Mr.        32.368090  0.156673\n",
      " Mrs.       35.898148  0.792000\n",
      " Ms.        28.000000  1.000000\n",
      " Rev.       43.166667  0.000000\n",
      " Sir.       49.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "sex_map = {\"male\":0,\"female\":0.5}\n",
    "embarked_map = {'S':0,'Q':0.5,'C':1}\n",
    "boolean_map = {False:0,True:1}\n",
    "title_map = {' Mr.':1, ' Mrs.':3,' Miss.':4, ' Master.':5, ' Don.':10, ' Rev.':10, ' Dr.':7, ' Mme.':1, ' Ms.':1,\n",
    " ' Major.':6, ' Lady.':1, ' Sir.':1, ' Mlle.':1, ' Col.':6, ' Capt.':10, ' Countess.':1,' Jonkheer.':10}\n",
    "\n",
    "special_title_map = {' Don.':1, ' Rev.':2.0, ' Major.':3, ' Col.':4,' Capt.':5.0, ' Mr.':6, ' Mrs.':7, ' Miss.':8, ' Master.':9,  ' Dr.':10,\n",
    "                     ' Mme.':11, ' Ms.':12,' Lady.':13, ' Sir.':14, ' Mlle.':15, ' Countess.':16,' Jonkheer.':17, ' Dona.':18}\n",
    "\n",
    "#각 feature를 전처리 하기 위한(숫자로 바꾸기 위한) dict자료형 \n",
    "\n",
    "train['Sex'] = train['Sex'].map(sex_map) #Sex에 대한 전처리 적용\n",
    "\n",
    "train['Embarked'] = train['Embarked'].map(embarked_map)#Embarked에 대한 전처리 적용\n",
    "train['Embarked'] = train['Embarked'].fillna(0)#누락된값이 2개밖에 없어 누락된 부분에 S를 넣음\n",
    "\n",
    "train['Cabin'] = train['Cabin'].notnull()\n",
    "train['Cabin'] = train['Cabin'].map(boolean_map)#Carbin에 대해 값이 존재하면 1, 누락되었으면 0을 적용\n",
    "\n",
    "train['Title'] = train['Name'].map(get_title)#Title column을 생성하여 Name으로부터 title을 추출하여 적용\n",
    "\n",
    "train['Specialtitle'] = train['Title'].map(special_title_map)#Specialtitle은 학습에 직접 적용될 title값. 기존의 title은 나이를 유추하는데 사용\n",
    "\n",
    "\n",
    "print(train[['Title','Age','Survived']].groupby(['Title']).mean())# title별 Age의 평균, 생존확률 확인\n",
    "\n",
    "#기존에 생존 확률 별 title을 binding 하여 feature로 사용하였으나, 오히려 정확도를 떨어뜨려 삭제함.\n",
    "\n",
    "train['Title'] = train['Title'].map(title_map) #title에 대한 전처리 과정\n",
    "\n",
    "train['Title'] = train['Title'].fillna(5)#title이 비어있으면 5를 넣음\n",
    "\n",
    "train['Age'] = train[['Age','Title']].apply(guess_age,axis=1)#비어있는 Age에 대해 각 title별 평균나이 적용\n",
    "\n",
    "test['Sex'] = test['Sex'].map(sex_map)\n",
    "test['Embarked'] = test['Embarked'].map(embarked_map)\n",
    "test['Embarked'] = test['Embarked'].fillna(0)\n",
    "test['Cabin'] = test['Cabin'].notnull()\n",
    "test['Cabin'] = test['Cabin'].map(boolean_map)\n",
    "test['Title'] = test['Name'].map(get_title)\n",
    "test['Specialtitle'] = test['Title'].map(special_title_map)\n",
    "test['Title'] = test['Title'].map(title_map)\n",
    "test['Title'] = test['Title'].fillna(5)\n",
    "test['Age'] = test[['Age','Title']].apply(guess_age,axis=1)\n",
    "test['Fare'] = test['Fare'].fillna(8)\n",
    "#Test Set에 대해서도 동일한 전처리 적용\n",
    "\n",
    "\n",
    "train['Age']=train['Age'].map(lambda x: x/30)\n",
    "train['Fare']=train['Fare'].map(lambda x: x/100)\n",
    "train['Pclass']=train['Pclass'].map(lambda x:x/3)\n",
    "train['SibSp']=train['SibSp'].map(lambda x: x/5)\n",
    "train['Parch']=train['Parch'].map(lambda x:x/5)\n",
    "test['Age']=test['Age'].map(lambda x: x/30)\n",
    "test['Fare']=test['Fare'].map(lambda x: x/100)\n",
    "test['Pclass']=test['Pclass'].map(lambda x:x/3)\n",
    "test['SibSp']=test['SibSp'].map(lambda x: x/5)\n",
    "test['Parch']=test['Parch'].map(lambda x:x/5)\n",
    "#각 데이터에 대해 중간값으로 나누어 스케일링함.\n",
    "\n",
    "\n",
    "train.drop('PassengerId',axis=1,inplace=True)\n",
    "train.drop('Name',axis=1,inplace=True)\n",
    "train.drop('Ticket',axis=1,inplace=True)\n",
    "train.drop('Title',axis=1,inplace=True)\n",
    "\n",
    "test.drop('Name',axis=1,inplace=True)\n",
    "test.drop('Ticket',axis=1,inplace=True)\n",
    "test.drop('Title',axis=1,inplace=True)\n",
    "test.drop('PassengerId',axis=1,inplace=True)\n",
    "#이제 학습을 위해 사용하지 않을 feature들을 drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from tensorflow.contrib import learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train['Survived']\n",
    "x_data = train[['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked','Specialtitle']]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_data,y_data,test_size=0.2,random_state=42) 해당 코드는 교차검증을 할 때 사용\n",
    "x_train = x_data\n",
    "y_train = y_data#train set의 x_data와 y_data 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-20173b51efda>:1: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:428: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmpzg4hszin\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000248CD0F65C0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\ljh_9\\\\AppData\\\\Local\\\\Temp\\\\tmpzg4hszin'}\n",
      "WARNING:tensorflow:From <ipython-input-8-20173b51efda>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-8-20173b51efda>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:509: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmpzg4hszin\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0513061, step = 1\n",
      "INFO:tensorflow:global_step/sec: 75.0779\n",
      "INFO:tensorflow:loss = 0.51626766, step = 101 (1.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9821\n",
      "INFO:tensorflow:loss = 0.4703166, step = 201 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.7737\n",
      "INFO:tensorflow:loss = 0.45118457, step = 301 (1.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3777\n",
      "INFO:tensorflow:loss = 0.42891648, step = 401 (1.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0665\n",
      "INFO:tensorflow:loss = 0.43617424, step = 501 (1.753 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 74.0169\n",
      "INFO:tensorflow:loss = 0.41683474, step = 601 (1.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2381\n",
      "INFO:tensorflow:loss = 0.42631176, step = 701 (1.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7962\n",
      "INFO:tensorflow:loss = 0.41933635, step = 801 (1.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2798\n",
      "INFO:tensorflow:loss = 0.4227364, step = 901 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8539\n",
      "INFO:tensorflow:loss = 0.4159038, step = 1001 (1.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8403\n",
      "INFO:tensorflow:loss = 0.4121674, step = 1101 (1.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1991\n",
      "INFO:tensorflow:loss = 0.4156713, step = 1201 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1404\n",
      "INFO:tensorflow:loss = 0.3982657, step = 1301 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3641\n",
      "INFO:tensorflow:loss = 0.41236994, step = 1401 (1.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.0677\n",
      "INFO:tensorflow:loss = 0.40057722, step = 1501 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5567\n",
      "INFO:tensorflow:loss = 0.40228668, step = 1601 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.6793\n",
      "INFO:tensorflow:loss = 0.3905855, step = 1701 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5362\n",
      "INFO:tensorflow:loss = 0.40065464, step = 1801 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2141\n",
      "INFO:tensorflow:loss = 0.40859962, step = 1901 (1.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7135\n",
      "INFO:tensorflow:loss = 0.39466134, step = 2001 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.2796\n",
      "INFO:tensorflow:loss = 0.40717837, step = 2101 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5841\n",
      "INFO:tensorflow:loss = 0.39034927, step = 2201 (1.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9186\n",
      "INFO:tensorflow:loss = 0.4063735, step = 2301 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2294\n",
      "INFO:tensorflow:loss = 0.38340396, step = 2401 (1.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.2533\n",
      "INFO:tensorflow:loss = 0.39150083, step = 2501 (1.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.7818\n",
      "INFO:tensorflow:loss = 0.38571814, step = 2601 (1.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.9788\n",
      "INFO:tensorflow:loss = 0.39507657, step = 2701 (1.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8852\n",
      "INFO:tensorflow:loss = 0.38380903, step = 2801 (1.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8152\n",
      "INFO:tensorflow:loss = 0.3875497, step = 2901 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1048\n",
      "INFO:tensorflow:loss = 0.38163915, step = 3001 (1.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0314\n",
      "INFO:tensorflow:loss = 0.38311446, step = 3101 (1.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8921\n",
      "INFO:tensorflow:loss = 0.38458365, step = 3201 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.6386\n",
      "INFO:tensorflow:loss = 0.38475424, step = 3301 (1.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4057\n",
      "INFO:tensorflow:loss = 0.38205218, step = 3401 (1.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0773\n",
      "INFO:tensorflow:loss = 0.38702488, step = 3501 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8375\n",
      "INFO:tensorflow:loss = 0.38258722, step = 3601 (2.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4553\n",
      "INFO:tensorflow:loss = 0.39342052, step = 3701 (4.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1591\n",
      "INFO:tensorflow:loss = 0.37805593, step = 3801 (2.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6869\n",
      "INFO:tensorflow:loss = 0.37953544, step = 3901 (3.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9832\n",
      "INFO:tensorflow:loss = 0.38174456, step = 4001 (2.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6436\n",
      "INFO:tensorflow:loss = 0.37983572, step = 4101 (3.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6516\n",
      "INFO:tensorflow:loss = 0.38301793, step = 4201 (4.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.4689\n",
      "INFO:tensorflow:loss = 0.3756531, step = 4301 (1.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7697\n",
      "INFO:tensorflow:loss = 0.38902232, step = 4401 (1.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3918\n",
      "INFO:tensorflow:loss = 0.38169166, step = 4501 (1.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1057\n",
      "INFO:tensorflow:loss = 0.37454742, step = 4601 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9674\n",
      "INFO:tensorflow:loss = 0.37976205, step = 4701 (1.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5161\n",
      "INFO:tensorflow:loss = 0.37711808, step = 4801 (1.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1472\n",
      "INFO:tensorflow:loss = 0.3853269, step = 4901 (2.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmpzg4hszin\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.37046897.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x00000248CD0F6FD0>, 'hidden_units': [20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=9, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x00000248C6A601E0>, 'dropout': 0.1, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "classifier = learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[20,20], n_classes=2,dropout=0.1)\n",
    "classifier.fit(x_train, y_train,steps=5000) #hidden layer 2층, dropout 0.1, Activation Func는 ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predicted = classifier.predict(x_test)\n",
    "#print(accuracy_score(y_test,list(predicted)))\n",
    "#해당 코드는 교차검증을 확인할 때 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:553: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:463: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmpzg4hszin\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(test)#생성된 모델로 결과 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         1\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\" : test.index+892,\n",
    "    #\"PassengerId\" : test[\"PassengerId\"],\n",
    "    \"Survived\" : list(result)\n",
    "})\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "#결과를 새로운 형태로 저장하여 Kaggle에 Submission\n",
    "print(submission)\n",
    "\n",
    "#최종 모델 교차검증 결과 약 0.81, Kaggle Score 0.79904(10000명 중 약 1300등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
