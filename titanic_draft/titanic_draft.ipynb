{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    match = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_age(cols):\n",
    "    age = cols[0]\n",
    "    title = cols[1]\n",
    "    if pd.isnull(age):\n",
    "        if title == 1:\n",
    "            return 32.376543\n",
    "        elif title == 3:\n",
    "            return 35.898148\n",
    "        elif title == 4:\n",
    "            return 21.773973\n",
    "        elif title == 5:\n",
    "            return 4.574167\n",
    "        elif title == 6:\n",
    "            return 53.250000\n",
    "        elif title == 7:\n",
    "            return 42.000000\n",
    "        elif title == 10:\n",
    "            return 45.222222\n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "#누락된 age값을 채우기 위해 각 title별 평균나이를 적용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Mr.' ' Mrs.' ' Miss.' ' Master.' ' Don.' ' Rev.' ' Dr.' ' Mme.' ' Ms.'\n",
      " ' Major.' ' Lady.' ' Sir.' ' Mlle.' ' Col.' ' Capt.' ' Countess.'\n",
      " ' Jonkheer.']\n",
      "[' Mr.' ' Mrs.' ' Miss.' ' Master.' ' Ms.' ' Col.' ' Rev.' ' Dr.' ' Dona.']\n",
      "   Survived    Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked  \\\n",
      "0         0  1.000000  0.0  0.733333    0.2    0.0  0.072500      0       0.0   \n",
      "1         1  0.333333  0.5  1.266667    0.2    0.0  0.712833      1       1.0   \n",
      "2         1  1.000000  0.5  0.866667    0.0    0.0  0.079250      0       0.0   \n",
      "3         1  0.333333  0.5  1.166667    0.2    0.0  0.531000      1       0.0   \n",
      "4         0  1.000000  0.0  1.166667    0.0    0.0  0.080500      0       0.0   \n",
      "\n",
      "   Specialtitle  \n",
      "0           6.0  \n",
      "1           7.0  \n",
      "2           8.0  \n",
      "3           7.0  \n",
      "4           6.0  \n",
      "     Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked  \\\n",
      "0  1.000000  0.0  1.150000    0.0    0.0  0.078292      0       0.5   \n",
      "1  1.000000  0.5  1.566667    0.2    0.0  0.070000      0       0.0   \n",
      "2  0.666667  0.0  2.066667    0.0    0.0  0.096875      0       0.5   \n",
      "3  1.000000  0.0  0.900000    0.0    0.0  0.086625      0       0.0   \n",
      "4  1.000000  0.5  0.733333    0.2    0.2  0.122875      0       0.0   \n",
      "\n",
      "   Specialtitle  \n",
      "0           6.0  \n",
      "1           7.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           7.0  \n"
     ]
    }
   ],
   "source": [
    "sex_map = {\"male\":0,\"female\":0.5}\n",
    "embarked_map = {'S':0,'Q':0.5,'C':1}\n",
    "boolean_map = {False:0,True:1}\n",
    "title_map = {' Mr.':1, ' Mrs.':3,' Miss.':4, ' Master.':5, ' Don.':10, ' Rev.':10, ' Dr.':7, ' Mme.':1, ' Ms.':1,\n",
    " ' Major.':6, ' Lady.':1, ' Sir.':1, ' Mlle.':1, ' Col.':6, ' Capt.':10, ' Countess.':1,' Jonkheer.':10}\n",
    "special_title_map = {' Don.':1, ' Rev.':2.0, ' Major.':3, ' Col.':4,' Capt.':5.0, ' Mr.':6, ' Mrs.':7, ' Miss.':8, ' Master.':9,  ' Dr.':10,\n",
    "                     ' Mme.':11, ' Ms.':12,' Lady.':13, ' Sir.':14, ' Mlle.':15, ' Countess.':16,' Jonkheer.':17, ' Dona.':18}\n",
    "#각 feature를 전처리 하기 위한(숫자로 바꾸기 위한) \n",
    "\n",
    "train['Sex'] = train['Sex'].map(sex_map)\n",
    "\n",
    "train['Embarked'] = train['Embarked'].map(embarked_map)\n",
    "train['Embarked'] = train['Embarked'].fillna(0)#누락된값이 2개밖에 없어서 그냥 S로 했습니다.\n",
    "\n",
    "train['Cabin'] = train['Cabin'].notnull()\n",
    "train['Cabin'] = train['Cabin'].map(boolean_map)\n",
    "\n",
    "train['Title'] = train['Name'].map(get_title)\n",
    "train['Specialtitle'] = train['Title'].map(special_title_map)\n",
    "\n",
    "\n",
    "print(train['Title'].unique())\n",
    "train[['Title','Age','Survived']].groupby(['Title']).mean()# title별 Age의 평균\n",
    "\n",
    "train['Title'] = train['Title'].map(title_map)\n",
    "#train[['Title','Age']].groupby(['Title']).mean()\n",
    "\n",
    "train['Title'] = train['Title'].fillna(5)\n",
    "train['Age'] = train[['Age','Title']].apply(guess_age,axis=1)#비어있는 Age에 대해 각 title별 평균나이 적용 했어요\n",
    "\n",
    "test['Sex'] = test['Sex'].map(sex_map)\n",
    "\n",
    "test['Embarked'] = test['Embarked'].map(embarked_map)\n",
    "test['Embarked'] = test['Embarked'].fillna(0)\n",
    "\n",
    "test['Cabin'] = test['Cabin'].notnull()\n",
    "test['Cabin'] = test['Cabin'].map(boolean_map)#Cabin의 경우에 기록 유무에만 따라 0 1 로 했어요\n",
    "\n",
    "test['Title'] = test['Name'].map(get_title)\n",
    "test['Specialtitle'] = test['Title'].map(special_title_map)\n",
    "print(test['Title'].unique())\n",
    "#test['Title'] = test['Title'].map(title_map)\n",
    "test['Title'] = test['Title'].map(title_map)\n",
    "test['Title'] = test['Title'].fillna(5)#이것두 Title의 조정 수치\n",
    "test['Age'] = test[['Age','Title']].apply(guess_age,axis=1)\n",
    "test['Fare'] = test['Fare'].fillna(8)\n",
    "\n",
    "train['Age']=train['Age'].map(lambda x: x/30)\n",
    "train['Fare']=train['Fare'].map(lambda x: x/100)\n",
    "train['Pclass']=train['Pclass'].map(lambda x:x/3)\n",
    "train['SibSp']=train['SibSp'].map(lambda x: x/5)\n",
    "train['Parch']=train['Parch'].map(lambda x:x/5)\n",
    "#train['Familycount']=train['SibSp']+train['Parch']\n",
    "#train['Familycount']=train['Familycount'].map(lambda x:x/6)\n",
    "#train.drop('SibSp',axis=1,inplace=True)\n",
    "#train.drop('Parch',axis=1,inplace=True)\n",
    "\n",
    "test['Age']=test['Age'].map(lambda x: x/30)\n",
    "test['Fare']=test['Fare'].map(lambda x: x/100)\n",
    "test['Pclass']=test['Pclass'].map(lambda x:x/3)\n",
    "test['SibSp']=test['SibSp'].map(lambda x: x/5)\n",
    "test['Parch']=test['Parch'].map(lambda x:x/5)\n",
    "#test['Familycount']=test['SibSp']+test['Parch']\n",
    "#test['Familycount']=test['Familycount'].map(lambda x:x/6)\n",
    "#test.drop('SibSp',axis=1,inplace=True)\n",
    "#test.drop('Parch',axis=1,inplace=True)\n",
    "\n",
    "train.drop('PassengerId',axis=1,inplace=True)\n",
    "train.drop('Name',axis=1,inplace=True)\n",
    "train.drop('Ticket',axis=1,inplace=True)\n",
    "train.drop('Title',axis=1,inplace=True)\n",
    "\n",
    "test.drop('Name',axis=1,inplace=True)\n",
    "test.drop('Ticket',axis=1,inplace=True)\n",
    "test.drop('Title',axis=1,inplace=True)\n",
    "test.drop('PassengerId',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#test_data=test.drop('PassengerId',axis=1).copy()\n",
    "#test['Pclass'] = StandardScaler().fit_transform(test['Pclass'].values.reshape(-1, 1))\n",
    "#test['Sex'] = StandardScaler().fit_transform(test['Sex'].values.reshape(-1, 1))\n",
    "#test['Age'] = StandardScaler().fit_transform(test['Age'].values.reshape(-1, 1))\n",
    "#test['SibSp'] = StandardScaler().fit_transform(test['SibSp'].values.reshape(-1, 1))\n",
    "#test['Parch'] = StandardScaler().fit_transform(test['Parch'].values.reshape(-1, 1))\n",
    "#test['Fare'] = StandardScaler().fit_transform(test['Fare'].values.reshape(-1, 1))\n",
    "#test['Cabin'] = StandardScaler().fit_transform(test['Cabin'].values.reshape(-1, 1))\n",
    "#test['Embarked'] = StandardScaler().fit_transform(test['Embarked'].values.reshape(-1, 1))\n",
    "#test['Specialtitle'] = StandardScaler().fit_transform(test['Specialtitle'].values.reshape(-1, 1))\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17620650953984288"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sex'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null float64\n",
      "Sex             891 non-null float64\n",
      "Age             891 non-null float64\n",
      "SibSp           891 non-null float64\n",
      "Parch           891 non-null float64\n",
      "Fare            891 non-null float64\n",
      "Cabin           891 non-null int64\n",
      "Embarked        891 non-null float64\n",
      "Specialtitle    891 non-null float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 69.7 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      "Pclass          418 non-null float64\n",
      "Sex             418 non-null float64\n",
      "Age             418 non-null float64\n",
      "SibSp           418 non-null float64\n",
      "Parch           418 non-null float64\n",
      "Fare            418 non-null float64\n",
      "Cabin           418 non-null int64\n",
      "Embarked        418 non-null float64\n",
      "Specialtitle    418 non-null float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 29.5 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from tensorflow.contrib import learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train['Survived']\n",
    "x_data = train[['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked','Specialtitle']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data,test_size=0.2,random_state=42)#교차검증 데이터셋\n",
    "x_train = x_data\n",
    "y_train = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmp6b3m3mll\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002B548B85630>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\ljh_9\\\\AppData\\\\Local\\\\Temp\\\\tmp6b3m3mll'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmp6b3m3mll\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0216849, step = 1\n",
      "INFO:tensorflow:global_step/sec: 69.7492\n",
      "INFO:tensorflow:loss = 0.5136274, step = 101 (1.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0103\n",
      "INFO:tensorflow:loss = 0.47062597, step = 201 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8139\n",
      "INFO:tensorflow:loss = 0.45979816, step = 301 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1619\n",
      "INFO:tensorflow:loss = 0.46388432, step = 401 (1.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2991\n",
      "INFO:tensorflow:loss = 0.45096016, step = 501 (1.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5583\n",
      "INFO:tensorflow:loss = 0.4330043, step = 601 (1.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.3937\n",
      "INFO:tensorflow:loss = 0.43788266, step = 701 (1.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1317\n",
      "INFO:tensorflow:loss = 0.41527662, step = 801 (1.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7059\n",
      "INFO:tensorflow:loss = 0.40863422, step = 901 (1.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.6119\n",
      "INFO:tensorflow:loss = 0.4178851, step = 1001 (1.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7927\n",
      "INFO:tensorflow:loss = 0.42535284, step = 1101 (1.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7056\n",
      "INFO:tensorflow:loss = 0.4093208, step = 1201 (1.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5054\n",
      "INFO:tensorflow:loss = 0.41025665, step = 1301 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8454\n",
      "INFO:tensorflow:loss = 0.41409263, step = 1401 (1.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6504\n",
      "INFO:tensorflow:loss = 0.40244314, step = 1501 (1.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7993\n",
      "INFO:tensorflow:loss = 0.40001464, step = 1601 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7019\n",
      "INFO:tensorflow:loss = 0.3881444, step = 1701 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8166\n",
      "INFO:tensorflow:loss = 0.400104, step = 1801 (1.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.4981\n",
      "INFO:tensorflow:loss = 0.40877506, step = 1901 (1.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3763\n",
      "INFO:tensorflow:loss = 0.3935159, step = 2001 (1.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7326\n",
      "INFO:tensorflow:loss = 0.40602356, step = 2101 (1.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2423\n",
      "INFO:tensorflow:loss = 0.389968, step = 2201 (1.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.2564\n",
      "INFO:tensorflow:loss = 0.39855266, step = 2301 (1.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.2938\n",
      "INFO:tensorflow:loss = 0.39213994, step = 2401 (1.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7102\n",
      "INFO:tensorflow:loss = 0.39251244, step = 2501 (1.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3984\n",
      "INFO:tensorflow:loss = 0.38902667, step = 2601 (1.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.173\n",
      "INFO:tensorflow:loss = 0.39590314, step = 2701 (1.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7038\n",
      "INFO:tensorflow:loss = 0.38841045, step = 2801 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7496\n",
      "INFO:tensorflow:loss = 0.3947521, step = 2901 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1376\n",
      "INFO:tensorflow:loss = 0.38580722, step = 3001 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3891\n",
      "INFO:tensorflow:loss = 0.39034337, step = 3101 (1.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9242\n",
      "INFO:tensorflow:loss = 0.3919208, step = 3201 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6729\n",
      "INFO:tensorflow:loss = 0.38302103, step = 3301 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.188\n",
      "INFO:tensorflow:loss = 0.38488686, step = 3401 (1.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9162\n",
      "INFO:tensorflow:loss = 0.38528946, step = 3501 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7823\n",
      "INFO:tensorflow:loss = 0.3854462, step = 3601 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7061\n",
      "INFO:tensorflow:loss = 0.3878709, step = 3701 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5653\n",
      "INFO:tensorflow:loss = 0.38687274, step = 3801 (1.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5325\n",
      "INFO:tensorflow:loss = 0.3845166, step = 3901 (1.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8707\n",
      "INFO:tensorflow:loss = 0.38281578, step = 4001 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.7372\n",
      "INFO:tensorflow:loss = 0.39499086, step = 4101 (1.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6905\n",
      "INFO:tensorflow:loss = 0.3906303, step = 4201 (1.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5291\n",
      "INFO:tensorflow:loss = 0.37755066, step = 4301 (1.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1834\n",
      "INFO:tensorflow:loss = 0.3823316, step = 4401 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6254\n",
      "INFO:tensorflow:loss = 0.38317505, step = 4501 (1.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.3279\n",
      "INFO:tensorflow:loss = 0.376219, step = 4601 (1.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3532\n",
      "INFO:tensorflow:loss = 0.38516405, step = 4701 (1.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5668\n",
      "INFO:tensorflow:loss = 0.38663015, step = 4801 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.0395\n",
      "INFO:tensorflow:loss = 0.38068724, step = 4901 (1.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmp6b3m3mll\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3747857.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x000002B548B79C50>, 'hidden_units': [20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=9, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x000002B536602BF8>, 'dropout': 0.1, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "classifier = learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[20,20], n_classes=2,dropout=0.1)\n",
    "classifier.fit(x_train, y_train,steps=5000) #hidden layer 3개의 초기 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmp6b3m3mll\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0.8603351955307262\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict(x_test)\n",
    "print(accuracy_score(y_test,list(predicted)))\n",
    "#교차검증 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ljh_9\\AppData\\Local\\Temp\\tmp6b3m3mll\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#x_train.to_csv('cut_xdata.csv')\n",
    "result = classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         1\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\" : test.index+892,\n",
    "    #\"PassengerId\" : test[\"PassengerId\"],\n",
    "    \"Survived\" : list(result)\n",
    "})\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "\n",
    "print(submission)\n",
    "\n",
    "\n",
    "#초기 모델 교차검증 0.8212290502793296 , Kaggle Score 0.78468(10000명 중 3944등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
